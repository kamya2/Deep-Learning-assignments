{"cells":[{"cell_type":"markdown","metadata":{},"source":"## Interesting Pytorch functions !"},{"cell_type":"markdown","metadata":{},"source":""},{"cell_type":"markdown","metadata":{},"source":""},{"cell_type":"markdown","metadata":{},"source":"**But what is pytorch?**\n\n\n**Pytorch is an open-source, Python-based machine and deep learning framework, which is being widely used for several natural language processing and computer vision applications.**\n**PyTorch was developed by Facebookâ€™s AI Research and is adapted by several industries like Uber, Twitter, Salesforce, and NVIDIA.**"},{"cell_type":"markdown","metadata":{},"source":"_Let's get started with some functions:_"},{"cell_type":"markdown","metadata":{},"source":"- torch.tensor()\n- torch.arange()\n- torch.narrow()\n- torch.rand()\n- torch.randit()"},{"cell_type":"markdown","metadata":{},"source":"**Also what is a Tensor?**"},{"cell_type":"markdown","metadata":{},"source":"**A tensor is a number, vector, matrix or any n-dimensional array. Pytorch library is required for processing tensors.**"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"# to install pytorch\n\n#!conda install pytorch cpuonly -c pytorch -y"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import torch"},{"cell_type":"markdown","metadata":{},"source":"## Function 1 ##"},{"cell_type":"markdown","metadata":{},"source":"*Torch.tensor() always copies data.*"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[4., 5.],\n","        [6., 7.]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":"# Example 1 \ntorch.tensor([[4,5], [6,7.]])"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"expected sequence of length 2 at dim 1 (got 3)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-a904fb44b8c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 1 - breaking point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 3)"]}],"source":"# Example 1 - breaking point\ntorch.tensor([[1, 2], [3, 4.,7.]])"},{"cell_type":"markdown","metadata":{},"source":"The dimensions of the vector should be same."},{"cell_type":"markdown","metadata":{},"source":"## Function 2 ##"},{"cell_type":"markdown","metadata":{},"source":"*Returns a 1-D tensor of size with values from the interval (start, end) taken with common difference.*"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0, 1, 2, 3, 4])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":"# Example 2 - working\ntorch.arange(5)"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1.0000, 2.5000, 4.0000])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":"# Example 2 (one more)\ntorch.arange(1, 5.5,1.5)"},{"cell_type":"markdown","metadata":{},"source":"*Returns a 1-D tensor of values from start to end with step. Step is the gap between two values in the tensor.Here the step is 1.5.*"},{"cell_type":"markdown","metadata":{},"source":"## Function 3 ##"},{"cell_type":"markdown","metadata":{},"source":"*Returns a new tensor that is a narrowed version of input tensor. The dimension dim is input from start to start + length.*"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[1, 2, 3],\n","        [4, 5, 6]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":"# Example 3 - working\nx = torch.tensor([[1, 2, 3], \n                  [4, 5, 6], \n                  [7, 8, 9]])\ntorch.narrow(x, 0, 0, 2)\n\n"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[2, 3],\n","        [5, 6],\n","        [8, 9]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":"torch.narrow(x, 1, 1, 2)"},{"cell_type":"markdown","metadata":{},"source":"## Function 4 ##"},{"cell_type":"markdown","metadata":{},"source":"*Returns a tensor filled with random numbers from a uniform distribution on the interval (0, 1)*.\n*The shape of the tensor is defined by the variable argument size.*"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0.9343, 0.4283, 0.3807, 0.6979, 0.5401])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":"# Example 4 - working\ntorch.rand(5)"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.3237, 0.1951, 0.8283],\n","        [0.4825, 0.4653, 0.4761],\n","        [0.6095, 0.1963, 0.4425]])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":"# Example 4 - (one more)\ntorch.rand(3,3)"},{"cell_type":"markdown","metadata":{},"source":"## Function 5 ##"},{"cell_type":"markdown","metadata":{},"source":"*Returns a tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive).*\n*The shape of the tensor is defined by the variable argument size.*"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[7, 9],\n","        [8, 4]])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":"# Example 5 - working\ntorch.randint(10, (2, 2))"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[1, 2],\n","        [4, 1]])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":"# Example 5 - (one more)\ntorch.randint(10, (2, 2))"},{"cell_type":"markdown","metadata":{},"source":"As you can see, the torch.randit() takes random values for defined low and high values and yes it's size too."},{"cell_type":"markdown","metadata":{},"source":"### Reference Links ###\n\n\nOfficial documentation for torch.Tensor: https://pytorch.org/docs/stable/tensors.html"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":2}